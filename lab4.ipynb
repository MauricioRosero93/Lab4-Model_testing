{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XHtaPysVSNZN"
   },
   "source": [
    "# Step 1 - Install the required dependencies and make sure the python version is 3.10 and above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "APS6D3eiSAR_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: zenoml in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (0.6.4)\n",
      "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (2.2.1)\n",
      "Requirement already satisfied: fastapi<0.101.0,>=0.95.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (0.100.1)\n",
      "Requirement already satisfied: uvicorn<0.24,>=0.22 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (0.23.2)\n",
      "Requirement already satisfied: inquirer<4.0.0,>=3.1.2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (3.4.0)\n",
      "Requirement already satisfied: pandas<3.0.0,>=2.0.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (2.2.3)\n",
      "Requirement already satisfied: pydantic<2.0.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (1.10.21)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.28.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (57.4.0)\n",
      "Requirement already satisfied: websockets<12.0,>=11.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (11.0.3)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (1.6.0)\n",
      "Requirement already satisfied: zeno-sliceline<0.0.2,>=0.0.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (0.0.1)\n",
      "Requirement already satisfied: pathos<0.4.0,>=0.3.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (0.3.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (4.67.1)\n",
      "Requirement already satisfied: opentsne<1.1.0,>=0.7.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from zenoml) (1.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from fastapi<0.101.0,>=0.95.1->zenoml) (4.12.2)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from fastapi<0.101.0,>=0.95.1->zenoml) (0.27.0)\n",
      "Requirement already satisfied: editor>=1.6.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from inquirer<4.0.0,>=3.1.2->zenoml) (1.6.6)\n",
      "Requirement already satisfied: blessed>=1.19.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from inquirer<4.0.0,>=3.1.2->zenoml) (1.20.0)\n",
      "Requirement already satisfied: readchar>=4.2.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from inquirer<4.0.0,>=3.1.2->zenoml) (4.2.1)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from blessed>=1.19.0->inquirer<4.0.0,>=3.1.2->zenoml) (1.17.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from blessed>=1.19.0->inquirer<4.0.0,>=3.1.2->zenoml) (0.2.13)\n",
      "Requirement already satisfied: jinxed>=1.1.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from blessed>=1.19.0->inquirer<4.0.0,>=3.1.2->zenoml) (1.3.0)\n",
      "Requirement already satisfied: xmod in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from editor>=1.6.0->inquirer<4.0.0,>=3.1.2->zenoml) (1.8.1)\n",
      "Requirement already satisfied: runs in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from editor>=1.6.0->inquirer<4.0.0,>=3.1.2->zenoml) (1.2.2)\n",
      "Requirement already satisfied: ansicon in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from jinxed>=1.1.0->blessed>=1.19.0->inquirer<4.0.0,>=3.1.2->zenoml) (1.89.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from opentsne<1.1.0,>=0.7.1->zenoml) (1.15.2)\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from opentsne<1.1.0,>=0.7.1->zenoml) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from opentsne<1.1.0,>=0.7.1->zenoml) (1.6.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pandas<3.0.0,>=2.0.0->zenoml) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pandas<3.0.0,>=2.0.0->zenoml) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pandas<3.0.0,>=2.0.0->zenoml) (2025.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.8 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pathos<0.4.0,>=0.3.0->zenoml) (1.7.6.9)\n",
      "Requirement already satisfied: pox>=0.3.4 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pathos<0.4.0,>=0.3.0->zenoml) (0.3.5)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pathos<0.4.0,>=0.3.0->zenoml) (0.70.16)\n",
      "Requirement already satisfied: dill>=0.3.8 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pathos<0.4.0,>=0.3.0->zenoml) (0.3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests<3.0.0,>=2.28.1->zenoml) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests<3.0.0,>=2.28.1->zenoml) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests<3.0.0,>=2.28.1->zenoml) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests<3.0.0,>=2.28.1->zenoml) (2025.1.31)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from scikit-learn>=0.20->opentsne<1.1.0,>=0.7.1->zenoml) (3.6.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from scikit-learn>=0.20->opentsne<1.1.0,>=0.7.1->zenoml) (1.4.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from starlette<0.28.0,>=0.27.0->fastapi<0.101.0,>=0.95.1->zenoml) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.101.0,>=0.95.1->zenoml) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi<0.101.0,>=0.95.1->zenoml) (1.2.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from tqdm<5.0.0,>=4.64.0->zenoml) (0.4.6)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from uvicorn<0.24,>=0.22->zenoml) (0.14.0)\n",
      "Requirement already satisfied: click>=7.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from uvicorn<0.24,>=0.22->zenoml) (8.1.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install zenoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (3.4.1)\n",
      "Requirement already satisfied: xxhash in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: fsspec[http]<=2024.12.0,>=2023.1.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (2024.12.0)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from aiohttp->datasets) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (4.49.0)Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: requests in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets\n",
    "%pip install transformers\n",
    "%pip install tqdm\n",
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CRrMiMnLV9xY",
    "outputId": "5193e819-f2cb-4032-99df-ced1ea7b4191",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.0\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Load a dataset from Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\datasets--cardiffnlp--tweet_eval. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 45615/45615 [00:00<00:00, 569263.43 examples/s]\n",
      "Generating test split: 100%|██████████| 12284/12284 [00:00<00:00, 567207.17 examples/s]\n",
      "Generating validation split: 100%|██████████| 2000/2000 [00:00<00:00, 102336.29 examples/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d8d28563-309b-4423-aa94-023328ee6c29",
       "rows": [
        [
         "0",
         "@user @user what do these '1/2 naked pics' have to do with anything? They're not even like that.",
         "1"
        ],
        [
         "1",
         "OH: “I had a blue penis while I was this” [playing with Google Earth VR]",
         "1"
        ],
        [
         "2",
         "@user @user That's coming, but I think the victims are going to be Medicaid recipients.",
         "1"
        ],
        [
         "3",
         "I think I may be finally in with the in crowd #mannequinchallenge  #grads2014 @user",
         "2"
        ],
        [
         "4",
         "@user Wow,first Hugo Chavez and now Fidel Castro. Danny Glover, Michael Moore, Oliver Stone, and Sean Penn are running out of heroes.",
         "0"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user @user what do these '1/2 naked pics' hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH: “I had a blue penis while I was this” [pla...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user @user That's coming, but I think the vic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I think I may be finally in with the in crowd ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@user Wow,first Hugo Chavez and now Fidel Cast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  @user @user what do these '1/2 naked pics' hav...      1\n",
       "1  OH: “I had a blue penis while I was this” [pla...      1\n",
       "2  @user @user That's coming, but I think the vic...      1\n",
       "3  I think I may be finally in with the in crowd ...      2\n",
       "4  @user Wow,first Hugo Chavez and now Fidel Cast...      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "ds = load_dataset(\"cardiffnlp/tweet_eval\", \"sentiment\")\n",
    "df = pd.DataFrame(ds['test']).head(500)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_map(x):\n",
    "    if x == 0:\n",
    "        return 'negative'\n",
    "    elif x == 1:\n",
    "        return 'neutral'\n",
    "    elif x == 2:\n",
    "        return 'positive'\n",
    "    return x\n",
    "df['label'] = df['label'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Run model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: This step is going to download two models of ~500MB each. \n",
    "\n",
    "**If you don't want to download the models, you can jump to step 4 and use the provided data in the repo instead.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with roberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment-latest. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Error while downloading from https://cas-bridge.xethub.hf.co/xet-bridge-us/622fea36174feb5439c2e4be/de96942de0344f84515de75d9e26290d81909535c2bfaa2513a5f520433cf3a4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250319%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250319T005754Z&X-Amz-Expires=3600&X-Amz-Signature=e8abdda93fbf5860afe069f2b2127c84f14b56bc2458cb2c979043b553052c43&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27pytorch_model.bin%3B+filename%3D%22pytorch_model.bin%22%3B&response-content-type=application%2Foctet-stream&x-id=GetObject&Expires=1742349474&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MjM0OTQ3NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MjJmZWEzNjE3NGZlYjU0MzljMmU0YmUvZGU5Njk0MmRlMDM0NGY4NDUxNWRlNzVkOWUyNjI5MGQ4MTkwOTUzNWMyYmZhYTI1MTNhNWY1MjA0MzNjZjNhNCoifV19&Signature=jTA4S6mHwH3FoW%7EdpKd%7EfDN0tFD6JkHWKMsSZZW%7Ey6LWPkLYE8PzhS%7EmieqTh79sNFjmNcZ9GGHzdvMIG2Mhw6Qhc4%7ESfYwqQ4x3tuw1fKn%7EXqARoCDx3japLL-qT-l8zLAR%7EpsIt0rqAs9R0%7E4gPa%7EYqQZpOwuiUMXDoolSGKeIPkmxwOcK6wmpe5A9Ole9437Dzve8pl%7EeNqTKiD83lfy8RVeR%7E0Q9AlhhDKkqBTOTWuffJBHv6mh9Bqqoux-AFk3Hnn3enF-POxKHtpGqKQhpC%7EEBD2mxZ3I8n3G9CQ0hk1JLw0HQtgX6U7Ifl%7EDud8qxWBz8e9rqBK7v26XFoQ__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Some weights of the model checkpoint at cardiffnlp/twitter-roberta-base-sentiment-latest were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cas-bridge.xethub.hf.co/xet-bridge-us/622fea36174feb5439c2e4be/2b6ef662a7c63db11fa1deb0ecb76497314862b60725166b376d7423b6769bb1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250319%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250319T005557Z&X-Amz-Expires=3600&X-Amz-Signature=be3ac16bb0df4d461e4b6eec32ae208a556a2e89659ff96c90c93ff7e25c6d23&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&x-id=GetObject&Expires=1742349357&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MjM0OTM1N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82MjJmZWEzNjE3NGZlYjU0MzljMmU0YmUvMmI2ZWY2NjJhN2M2M2RiMTFmYTFkZWIwZWNiNzY0OTczMTQ4NjJiNjA3MjUxNjZiMzc2ZDc0MjNiNjc2OWJiMSoifV19&Signature=hPcCBDnIcA5qS2TOQK0xKVHFOGU0xr7ZZk2rLaITveezApsmfx5auliBjOe-hBe5%7EmLzF4m2bieH1wOLIX27LUg2PSUd3eiBbIkQQVeX5L7lkSwWUxFw6Efj9fOk01osxf9W8mMnAXMUuw5rtLLrTljYzXomOR97tGSmp7RVyXpydrx-kPCMcdYdWrGuTX1h5ktOfR8Zs4f472jPwvHaDy7hOgtmZCzY7Ze4U8qToahKDcx2onAescf9L4x4gnlSYtps9dfJAAGVpEocROswSlHE6hPmwMv0R%7E%7Ee5XZ07Zhgn3XlBjV%7EElyNKV3-wgL6ZYmPTj5bLk3uyUIL3nF%7Ejg__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"cardiffnlp/twitter-roberta-base-sentiment-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:26<00:00, 18.72it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "results = []\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "## Depending on your machine, this should take around 1 minute\n",
    "for text in tqdm.tqdm(texts):\n",
    "    results.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['roberta'] = [r[0]['label'] for r in results]\n",
    "df['roberta_score'] = [r[0]['score'] for r in results]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run inference with gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Asus\\.cache\\huggingface\\hub\\models--LYTinn--finetuning-sentiment-model-tweet-gpt2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"LYTinn/finetuning-sentiment-model-tweet-gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:24<00:00, 20.18it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "results = []\n",
    "texts = df['text'].to_list()\n",
    "\n",
    "## Depending on your machine, this should take around 1 minute\n",
    "for text in tqdm.tqdm(texts):\n",
    "    results.append(pipe(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gpt2'] = [r[0]['label'] for r in results]\n",
    "df['gpt2_score'] = [r[0]['score'] for r in results]\n",
    "\n",
    "## map labels back\n",
    "def label_map(x):\n",
    "    if x == 'LABEL_0':\n",
    "        return 'negative'\n",
    "    elif x == 'LABEL_1':\n",
    "        return 'neutral'\n",
    "    elif x == 'LABEL_2':\n",
    "        return 'positive'\n",
    "    return x\n",
    "df['gpt2'] = df['gpt2'].map(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 - Pre-processing data and add additional columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## If you skip the model inference, uncomment the code below and load the provided data\n",
    "\n",
    "# df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"input_length\"] = df[\"text\"].str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 - Start Zeno for interactive slicing\n",
    "\n",
    "In this step, you need to create 5 slices in the Zeno interface and derive meaningful insights.\n",
    "\n",
    "As a starting point, try to create the two slices we provide:\n",
    "\n",
    "1. Tweets with hashtags\n",
    "2. Tweets with strong positive words (e.g., love) -- you can determine the exact words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating slices in Zeno is straightforward: Just click on the '+' button for 'create a new slice', and you can define the slice using existing column attributes, with simple value macthing or even regular expression.\n",
    "\n",
    "![image.png](images/image.png)\n",
    "\n",
    "There are more fun features in Zeno, including interactive metadata & model comparison -- feel free to check the teaser video in [README](https://github.com/zeno-ml/zeno) of the Zeno repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: no id_column specified, using index as id_column. If you are using a data_column, suggest using it as id_column.\n"
     ]
    }
   ],
   "source": [
    "## Execute the code here to start a local Zeno server\n",
    "\n",
    "from zeno import zeno\n",
    "\n",
    "from zeno.api import model, distill, metric\n",
    "from zeno.api import ModelReturn, MetricReturn, DistillReturn, ZenoOptions\n",
    "\n",
    "@model\n",
    "def load_model(model_name):\n",
    "    \n",
    "    def pred(df, ops: ZenoOptions):\n",
    "        out = df[model_name]\n",
    "        return ModelReturn(model_output=out)\n",
    "\n",
    "    return pred\n",
    "\n",
    "@distill\n",
    "def label_match(df, ops: ZenoOptions):\n",
    "    results = (df[ops.label_column] == df[ops.output_column]).to_list()\n",
    "    return DistillReturn(distill_output=results)\n",
    "\n",
    "@metric\n",
    "def accuracy(df, ops: ZenoOptions):\n",
    "    avg = df[ops.distill_columns[\"label_match\"]].mean()\n",
    "    return MetricReturn(metric=avg)\n",
    "\n",
    "zeno({\n",
    "    \"metadata\": df, # Pandas DataFrame with a row for each instance\n",
    "    \"view\": \"text-classification\", # The type of view for this data/task\n",
    "    \"data_column\": \"text\", \n",
    "    \"label_column\": \"label\",\n",
    "    \"functions\": [load_model, label_match, accuracy],\n",
    "    \"models\": [\"roberta\", \"gpt2\"],\n",
    "    \"port\": 8001\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully updated project.\n",
      "Access your project at  https://hub.zenoml.com/project/9c2fce08-c949-48fc-acb8-962495be9419/Tweet%20Sentiment%20Analysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Asus\\cmu-mlip-model-testing-lab\\mlip-lab4\\lib\\site-packages\\zeno_client\\util.py:25: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '['0' '1' '2' '3' '4' '5' '6' '7' '8' '9' '10' '11' '12' '13' '14' '15'\n",
      " '16' '17' '18' '19' '20' '21' '22' '23' '24' '25' '26' '27' '28' '29'\n",
      " '30' '31' '32' '33' '34' '35' '36' '37' '38' '39' '40' '41' '42' '43'\n",
      " '44' '45' '46' '47' '48' '49' '50' '51' '52' '53' '54' '55' '56' '57'\n",
      " '58' '59' '60' '61' '62' '63' '64' '65' '66' '67' '68' '69' '70' '71'\n",
      " '72' '73' '74' '75' '76' '77' '78' '79' '80' '81' '82' '83' '84' '85'\n",
      " '86' '87' '88' '89' '90' '91' '92' '93' '94' '95' '96' '97' '98' '99'\n",
      " '100' '101' '102' '103' '104' '105' '106' '107' '108' '109' '110' '111'\n",
      " '112' '113' '114' '115' '116' '117' '118' '119' '120' '121' '122' '123'\n",
      " '124' '125' '126' '127' '128' '129' '130' '131' '132' '133' '134' '135'\n",
      " '136' '137' '138' '139' '140' '141' '142' '143' '144' '145' '146' '147'\n",
      " '148' '149' '150' '151' '152' '153' '154' '155' '156' '157' '158' '159'\n",
      " '160' '161' '162' '163' '164' '165' '166' '167' '168' '169' '170' '171'\n",
      " '172' '173' '174' '175' '176' '177' '178' '179' '180' '181' '182' '183'\n",
      " '184' '185' '186' '187' '188' '189' '190' '191' '192' '193' '194' '195'\n",
      " '196' '197' '198' '199' '200' '201' '202' '203' '204' '205' '206' '207'\n",
      " '208' '209' '210' '211' '212' '213' '214' '215' '216' '217' '218' '219'\n",
      " '220' '221' '222' '223' '224' '225' '226' '227' '228' '229' '230' '231'\n",
      " '232' '233' '234' '235' '236' '237' '238' '239' '240' '241' '242' '243'\n",
      " '244' '245' '246' '247' '248' '249' '250' '251' '252' '253' '254' '255'\n",
      " '256' '257' '258' '259' '260' '261' '262' '263' '264' '265' '266' '267'\n",
      " '268' '269' '270' '271' '272' '273' '274' '275' '276' '277' '278' '279'\n",
      " '280' '281' '282' '283' '284' '285' '286' '287' '288' '289' '290' '291'\n",
      " '292' '293' '294' '295' '296' '297' '298' '299' '300' '301' '302' '303'\n",
      " '304' '305' '306' '307' '308' '309' '310' '311' '312' '313' '314' '315'\n",
      " '316' '317' '318' '319' '320' '321' '322' '323' '324' '325' '326' '327'\n",
      " '328' '329' '330' '331' '332' '333' '334' '335' '336' '337' '338' '339'\n",
      " '340' '341' '342' '343' '344' '345' '346' '347' '348' '349' '350' '351'\n",
      " '352' '353' '354' '355' '356' '357' '358' '359' '360' '361' '362' '363'\n",
      " '364' '365' '366' '367' '368' '369' '370' '371' '372' '373' '374' '375'\n",
      " '376' '377' '378' '379' '380' '381' '382' '383' '384' '385' '386' '387'\n",
      " '388' '389' '390' '391' '392' '393' '394' '395' '396' '397' '398' '399'\n",
      " '400' '401' '402' '403' '404' '405' '406' '407' '408' '409' '410' '411'\n",
      " '412' '413' '414' '415' '416' '417' '418' '419' '420' '421' '422' '423'\n",
      " '424' '425' '426' '427' '428' '429' '430' '431' '432' '433' '434' '435'\n",
      " '436' '437' '438' '439' '440' '441' '442' '443' '444' '445' '446' '447'\n",
      " '448' '449' '450' '451' '452' '453' '454' '455' '456' '457' '458' '459'\n",
      " '460' '461' '462' '463' '464' '465' '466' '467' '468' '469' '470' '471'\n",
      " '472' '473' '474' '475' '476' '477' '478' '479' '480' '481' '482' '483'\n",
      " '484' '485' '486' '487' '488' '489' '490' '491' '492' '493' '494' '495'\n",
      " '496' '497' '498' '499']' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.loc[:, id_column] = df[id_column].astype(str)\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.77s/it]\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_24900\\3894714715.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_system[\"correct\"] = (df_system[model] == df[\"label\"]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.73s/it]\n",
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_24900\\3894714715.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_system[\"correct\"] = (df_system[model] == df[\"label\"]).astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully uploaded system\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from zeno_client import ZenoClient, ZenoMetric\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('tweets.csv')\n",
    "df = df.reset_index()\n",
    "\n",
    "# Initialize a client with the API key.\n",
    "client = ZenoClient(\"zen_l626bn2DRTA-MHdeURwCSGPzoJCk98oL617b4B53a2g\")\n",
    "\n",
    "project = client.create_project(\n",
    "    name=\"Tweet Sentiment Analysis\",\n",
    "    view=\"text-classification\",\n",
    "    metrics=[\n",
    "        ZenoMetric(name=\"accuracy\", type=\"mean\", columns=[\"correct\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "project.upload_dataset(df, id_column=\"index\", data_column=\"text\", label_column=\"label\")\n",
    "\n",
    "models = ['roberta', 'gpt2']\n",
    "for model in models:\n",
    "    df_system = df[['index', model]]\n",
    "    \n",
    "    # Measure accuracy for each instance, which is averaged by the ZenoMetric above\n",
    "    df_system[\"correct\"] = (df_system[model] == df[\"label\"]).astype(int)\n",
    "    \n",
    "    project.upload_system(df_system, name=model, id_column=\"index\", output_column=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running the code above, you should be able to access Zeno in http://localhost:8231"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After successfully creating the two slices, come up with three *additional* slices you want to check and **create** the slices in the Zeno interface.\n",
    "\n",
    "There are two directions to identify useful slices:\n",
    "- Top-down: Think about what kinds of things the model can struggle with, and come up with some slices.\n",
    "- Bottom-up: Look at model (mis-)predictions, come up with hypotheses, and translate them into data slices.\n",
    "\n",
    "3. [YOUR CHOICE]\n",
    "4. [YOUR CHOICE]\n",
    "5. [YOUR CHOICE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down descriptions of additional slices you created\n",
    "\n",
    "custom_slice_descriptions = [\n",
    "    \"Tweets neutrales\",\n",
    "    \"Tweets positivos\",\n",
    "    \"Tweets negativos\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 - Write down three addition data slices you want to create but do not have the metadata for slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, you might have already come up with some slices you wanted to create but found it hard to do with existing metadata. Write down three of such slices in this step.\n",
    "\n",
    "Example: \n",
    "- I want to create a slice on tweets using slangs\n",
    "- I want to create a slice on non-English tweets (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down three additional data slices here:\n",
    "\n",
    "additional_slice_descriptions = [\n",
    "    \"Tweets con emojis\",\n",
    "    \"Tweets cortos\",\n",
    "    \"Tweets con menciones\" \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 - Generate more test cases with Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select one slice from the three you wrote down and generate **10 test cases** using LLMs, which can include average case, boundary case, or difficult case.\n",
    "\n",
    "Your input can be in the following format:\n",
    "\n",
    "> Examples:\n",
    "> - OH: “I had a blue penis while I was this” [playing with Google Earth VR]\n",
    "> - @user @user That’s coming, but I think the victims are going to be Medicaid recipients.\n",
    "> - I think I may be finally in with the in crowd #mannequinchallenge  #grads2014 @user\n",
    "> \n",
    "> Generate more tweets using slangs.\n",
    "\n",
    "The first part of **Examples** conditions the LLM on the style, length, and content of examples. The second part of **Instructions** instructs what kind of examples you want LLM to generate.\n",
    "\n",
    "Use our provided GPTs to start the task: [llm-based-test-case-generator](https://chatgpt.com/g/g-982cylVn2-llm-based-test-case-generator). If you do not have access to GPTs, use the plain ChatGPT or other LLM providers you have access to instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write down the slice you select\n",
    "\n",
    "slice_description = \"Tweets con hashtags\"\n",
    "\n",
    "## Write down all generated test cases here\n",
    "\n",
    "generated_test_cases = [\n",
    "    \"🌱💡 ¡Pequeñas acciones pueden generar grandes cambios! Hoy es un buen día para hacer algo positivo por el planeta. 🌍♻️ #CuidemosNuestroHogar #ActúaHoy\",\n",
    "    \"🚀 Nunca es tarde para aprender algo nuevo. ¡Cada día es una oportunidad para crecer! 📚✨ #AprendizajeConstante #SigueAdelante\",  \n",
    "    \"🏆 La perseverancia es la clave del éxito. Si hoy caes, mañana te levantas con más fuerza. 💪🔥 #NuncaTeRindas #PasosFirmes\",\n",
    "    \"🐶💖 Nada mejor que la lealtad y amor incondicional de un amigo de cuatro patas. ¡Agradece su compañía! 🐾 #AmorPerruno #FamiliaPeluda\",\n",
    "    \"☕✨ Un café y una actitud positiva pueden cambiar tu día. ¡Vamos con todo! 🚀 #BuenosDías #EnergíaPositiva\",\n",
    "    \"A veces, solo necesitas tu canción favorita para mejorar el día. ¿Cuál es la tuya? 🎵😊 #MúsicaParaElAlma #FelizDía\",\n",
    "    \"💡 Pequeños logros también cuentan. Celebra cada paso que te acerque a tu meta. 🎯🎉 #SigueAvanzando #PequeñosTriunfos\",\n",
    "    \"🌈 La vida es un viaje lleno de aprendizajes. Disfruta el camino y sigue brillando. ✨😊 #ActitudPositiva #DisfrutaElMomento\",\n",
    "    \"💙 Siempre hay alguien a quien puedes hacer sonreír. ¡Sé esa persona hoy! 😊💕 #ComparteAlegría #HazElBien\",\n",
    "    \"🌅 Hoy es un nuevo comienzo, una nueva oportunidad para dar lo mejor de ti. ¡Aprovechémosla al máximo! 🚀🌟 #NuevaOportunidad #ViveIntensamente\"\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mlip-lab4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
